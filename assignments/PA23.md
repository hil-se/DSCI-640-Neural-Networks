[<img width=900 src="../img/title.png?raw=yes">](../README.md)   
[Syllabus](../README.md) |
[Slides and Assignments](README.md) |
[Project](project.md) |
[Lecturer](http://zhe-yu.github.io) 


PA2-3 will be focused on completing the additional forward and backward pass functionality to be able to train RNNs for time series prediction, and being able to run the GradientDescent.java program.

Programming Assignment 2 is 15% of your final grade, and Part 3 is 25% of that. This will be graded out of 5 points.




1. (2 points) Complete the min/max normalization which will scale all the time series values down to between 0 and 1 by subtracting the min and dividing by the max-min. You will need to complete TimeSeriesDataSet.getMins, getMaxs, normalizeMinMax as well as the TimeSeries.normalizeMinMax helper function.

2. (2 points) Complete the loss functions for regression (L1_NORM and L2_NORM) in RecurrentNeuralNetwork.forward pass.

3. (1 point) Complete the batch, minibatch and stochastic gradient descent methods in GradientDescent, using nesterov momentum (similar to the PA1-3).







In completing the above, none of your changes should break the unit tests in BasicTests.java, PA21Tests.java or PA22Tests.java. You should be able to successfully complete all the PA23Tests.java. Additionally you should be able to successfully run the GradientDescent.java program for any network and data type, example usage and parameters:

java GradientDescent flights_small sigmoid jordan kaiming stochastic 2 l2_norm 50 0.0 0.005 0.5 0.05 1.0 10

java GradientDescent penn_small sigmoid jordan kaiming stochastic 2 softmax 50 0.0 0.005 0.5 0.05 1.0 48




The methods you need to complete are marked with TODO in a comment, so you can find them and the line they are on with the following command (run from within the pa23 directory):

grep -n 'TODO' ./*/*.java
